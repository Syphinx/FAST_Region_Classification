{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syphinx/FAST_Region_Classification/blob/main/Thesis_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0jHOWDOwaZI",
        "outputId": "98aa3203-38cd-42c7-a207-a95c7ae715f8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYGiiJVScSv4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import apply_affine_transform\n",
        "from keras.models import load_model, Sequential, Model\n",
        "from keras.layers import average, TimeDistributed, GlobalAveragePooling1D, concatenate, Dense, CuDNNLSTM, Dropout\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BN9FWiht5an",
        "outputId": "1cde9996-eed7-4666-c1f3-e08a15e0e3fd"
      },
      "outputs": [],
      "source": [
        "!mkdir comp4906\n",
        "!mkdir comp4906/Data\n",
        "!mkdir comp4906/Models\n",
        "!cp -r drive/MyDrive/comp4906/2022_12_09_tarred_slices.tar.gz comp4906\n",
        "!cp -r drive/MyDrive/Models/* comp4906/Models\n",
        "!tar -xvf comp4906/2022_12_09_tarred_slices.tar.gz --directory comp4906/Data\n",
        "%cd comp4906\n",
        "!mv Data/home/holden/scratch/fast_sliced/* Data\n",
        "!rm -rf Data/home"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIKkz1ki15vj"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ21IOSA2THt"
      },
      "outputs": [],
      "source": [
        "class FusedModelGenerator:\n",
        "    def __init__(self, train_dir, test_dir, filter=None, num_of_snip=10, num_of_snip_spatial=1, opt_flow_len=10, batch_size=16, fileext_opticalflow=\".jpg\",\n",
        "                 fileext_spatial=\".jpg\", spatial_input_name = 'spatial_input'):\n",
        "        self.train_dir = train_dir\n",
        "        self.test_dir = test_dir\n",
        "        print(f\"Generating from {self.train_dir} / {self.test_dir}\")\n",
        "        self.filter = filter\n",
        "        self.n_snips = num_of_snip\n",
        "        self.n_snips_spatial = num_of_snip\n",
        "        self.opt_flow_len = opt_flow_len\n",
        "        self.batch_size = batch_size\n",
        "        self.fileext_opticalflow = fileext_opticalflow\n",
        "        self.fileext_spatial = fileext_spatial\n",
        "        self.spatial_input_name = spatial_input_name\n",
        "\n",
        "        # File refers to a scan  (A class)\n",
        "        self.classname_by_id = {i: file for i, file in enumerate(os.listdir(self.train_dir)) if\n",
        "                                os.path.isdir(os.path.join(self.train_dir, file))}\n",
        "        self.id_by_classname = {cls: i for i, cls in self.classname_by_id.items()}\n",
        "        self.n_classes = len(self.classname_by_id)\n",
        "\n",
        "        self.videopaths_opticalflow_train = self.get_videonames(self.train_dir)  # Includes class folder in path\n",
        "        self.n_train = len(self.videopaths_opticalflow_train)\n",
        "        self.videopaths_opticalflow_test = self.get_videonames(self.test_dir)\n",
        "        self.n_test = len(self.videopaths_opticalflow_test)\n",
        "\n",
        "        self.count = 0\n",
        "\n",
        "  \n",
        "\n",
        "    def _augment(self, image, row_axis = 0, col_axis = 1, channel_axis=2):\n",
        "        # AFFINE\n",
        "        # print('LINE 40 in AUGMENT FUNCTION: ', image.shape[col_axis])\n",
        "        image = apply_affine_transform(image,\n",
        "                                       theta=np.random.uniform(-5,5),\n",
        "                                       tx=np.random.uniform(-0.1,0.1) * image.shape[col_axis],\n",
        "                                       ty=np.random.uniform(-0.1,0.1) * image.shape[row_axis],\n",
        "                                       shear=np.random.uniform(-5, 5),\n",
        "                                       zx=np.random.uniform(0.9,1.1),\n",
        "                                       zy=np.random.uniform(0.9,1.1),\n",
        "                                       row_axis=row_axis,\n",
        "                                       col_axis=col_axis,\n",
        "                                       channel_axis=channel_axis,\n",
        "                                       fill_mode='nearest',\n",
        "                                       cval=0,\n",
        "                                       order=1)\n",
        "        return image\n",
        "\n",
        "    def get_videonames(self, directory):\n",
        "        # videonames is a list of paths to a video (single scan data point)\n",
        "        videonames = []\n",
        "        for classid, classdir in self.classname_by_id.items():\n",
        "            # Directory = Whole train folder\n",
        "            # Classdir refers to a scan (A class)\n",
        "            # File here refers to a video (A folder of the images/flow data) in a Scan (Classdir)\n",
        "\n",
        "            # videonames.extend([os.path.join(classdir, file) for file in os.listdir(os.path.join(directory, classdir)) if\n",
        "            #                    os.path.isdir(os.path.join(directory, classdir, file))])\n",
        "            videonames.extend([os.path.join(classdir, file) for file in os.listdir(os.path.join(directory, classdir)) if\n",
        "                               os.path.isdir(os.path.join(directory, classdir, file))])\n",
        "        if self.filter:\n",
        "            n_videos = len(videonames)\n",
        "            videonames = [video for video in videonames if self.filter in video]\n",
        "            print(f'Filtering by {self.filter}; {n_videos} -> {len(videonames)}')\n",
        "\n",
        "        return videonames\n",
        "\n",
        "    def generate_stacks(self, train_or_test):\n",
        "        while True:\n",
        "\n",
        "            if train_or_test == \"train\":\n",
        "                data_dir = self.train_dir\n",
        "                videonames = self.videopaths_opticalflow_train\n",
        "                random.shuffle(videonames) # Only shuffle training samples\n",
        "                augment = True\n",
        "            elif train_or_test == 'test':\n",
        "                data_dir = self.test_dir\n",
        "                videonames = self.videopaths_opticalflow_test\n",
        "                augment = False\n",
        "            else:\n",
        "                raise ValueError(\"train_or_test must be 'train' or 'test'\")\n",
        "\n",
        "            n_batches = int(len(videonames) / self.batch_size)\n",
        "            for i in range(n_batches):\n",
        "                x, y = {'temporal_input': [], self.spatial_input_name: []}, []\n",
        "\n",
        "                videonames_batch = videonames[i * self.batch_size:(i + 1) * self.batch_size]\n",
        "                for _ in range(self.batch_size):\n",
        "                    videoname = videonames_batch.pop(0)\n",
        "                    videopath = os.path.join(data_dir, videoname)\n",
        "\n",
        "                    seires_optical_stacks = self.get_series_of_optical_flow_stacks(videopath, augment)\n",
        "\n",
        "                    series_spatial_images = self.get_series_of_spatial_images(videopath, augment)\n",
        "\n",
        "                    onehot_class = to_categorical(self.id_by_classname[os.path.basename(os.path.dirname(videopath))], self.n_classes)\n",
        "\n",
        "                    x['temporal_input'].append(seires_optical_stacks)\n",
        "                    x[self.spatial_input_name].append(series_spatial_images)\n",
        "                    y.append(onehot_class)\n",
        "\n",
        "                try:\n",
        "                    x['temporal_input'] = np.stack(x['temporal_input'])\n",
        "                    x[self.spatial_input_name] = np.stack(x[self.spatial_input_name])\n",
        "                    y = np.stack(y)\n",
        "                except ValueError:\n",
        "                    'Bigman we get an error here'\n",
        "                yield x, y\n",
        "\n",
        "    def get_series_of_optical_flow_stacks(self, directory, augment):\n",
        "        series_optical_flow_stacks = []\n",
        "\n",
        "        # starting_frame = 0\n",
        "        fc = len([entry for entry in os.listdir(directory) if os.path.isfile(os.path.join(directory, entry))])/3\n",
        "        starting_frame = np.random.randint(fc-(self.opt_flow_len*self.n_snips))\n",
        "        self.count = 0\n",
        "\n",
        "        #N_snips == Chunks per video\n",
        "        for i in range(self.n_snips):\n",
        "\n",
        "            optical_flow_stack = []\n",
        "            _from = starting_frame + (self.opt_flow_len * i)\n",
        "            _to = starting_frame + (self.opt_flow_len * (i + 1))\n",
        "\n",
        "            if i == 0: # Make sure frame 0 is skipped as no flow info; this means iter0 is 1-10, and iter1 10-19\n",
        "                _from += 1\n",
        "                _to += 1\n",
        "            selected_frames = range(_from, _to)\n",
        "            NoneCheck = False\n",
        "            # print(f\"Snip {i}: frames: {selected_frames}\")\n",
        "            for i_frame in selected_frames:\n",
        "                filename_x = os.path.join(directory, f\"flow_x_{i_frame:05d}{self.fileext_opticalflow}\")\n",
        "                img_x = cv2.imread(filename_x, 0)\n",
        "\n",
        "                try:\n",
        "                    img_x = img_x / 255.\n",
        "                except TypeError:\n",
        "                    NoneCheck = True\n",
        "                    print(f\"Failed to load {i_frame} from {directory} from frames {selected_frames}\")\n",
        "\n",
        "\n",
        "                filename_y = os.path.join(directory, f\"flow_y_{i_frame:05d}{self.fileext_opticalflow}\")\n",
        "                img_y = cv2.imread(filename_y, 0)\n",
        "\n",
        "                # noinspection PyUnresolvedReferences,PyProtectedMember\n",
        "                try:\n",
        "                    img_y = np.swapaxes(img_y, 0, 1)\n",
        "                    img_y = img_y / 255.\n",
        "                except np.AxisError:\n",
        "                    print(f\"Axis error when loading {i_frame} from {directory}: img_y: {img_y}\\nimg_x was {img_x}\")\n",
        "\n",
        "                if not NoneCheck:\n",
        "                    optical_flow_stack.append(img_x)\n",
        "                    optical_flow_stack.append(img_y)\n",
        "                    self.count +=1\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            if NoneCheck:\n",
        "                break\n",
        "\n",
        "            optical_flow_stack = np.array(optical_flow_stack)\n",
        "            optical_flow_stack = np.swapaxes(optical_flow_stack, 0, 1)\n",
        "            optical_flow_stack = np.swapaxes(optical_flow_stack, 1, 2)\n",
        "\n",
        "            if augment:\n",
        "                optical_flow_stack = self._augment(optical_flow_stack)\n",
        "            # print('Shape of stack: ', optical_flow_stack.shape)\n",
        "            series_optical_flow_stacks.append(optical_flow_stack)\n",
        "        #   series_optical_flow_stacks shape  = [chunks per vid (n_snips), 224, 224, 2*(flow length)]\n",
        "        r = np.stack(series_optical_flow_stacks)\n",
        "        # print('Length of series optical flow stack: ', len(r))\n",
        "        return r\n",
        "\n",
        "    def get_series_of_spatial_images(self, dir, augment):\n",
        "        series_spatial_images = []\n",
        "\n",
        "        if self.n_snips_spatial == self.n_snips:\n",
        "            selected_frames = [i*self.opt_flow_len for i in range(self.n_snips)]\n",
        "            # print('Selected frames = ', selected_frames)\n",
        "        else:\n",
        "            selected_frames = np.linspace(0,self.opt_flow_len * self.n_snips - 1,20, dtype=np.uint)\n",
        "            # selected_frames = range(self.n_snips_spatial)\n",
        "\n",
        "        # print(\"Self.count is EQUALS to:\", self.count)\n",
        "        # selected_frames = range(self.count)\n",
        "\n",
        "\n",
        "        for i_frame in selected_frames:\n",
        "            filename_spatial = os.path.join(dir, f\"img_{i_frame+1:05d}{self.fileext_spatial}\")\n",
        "            img_spatial = cv2.imread(filename_spatial, 1)\n",
        "\n",
        "            if augment:\n",
        "                img_spatial = self._augment(img_spatial)\n",
        "\n",
        "            img_spatial = img_spatial / 255.\n",
        "            series_spatial_images.append(img_spatial)\n",
        "\n",
        "        series_spatial_images = np.array(series_spatial_images)\n",
        "        # print('Series Spatial images shape = ', series_spatial_images.shape)\n",
        "        return series_spatial_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3Y--3903llU"
      },
      "outputs": [],
      "source": [
        "class TwoStreamFused():\n",
        "    def __init__(self, spatial_model_name, temporal_model_name,\n",
        "                 train_dir, test_dir,\n",
        "                 width_temporal, height_temporal,\n",
        "                 width_spatial, height_spatial,\n",
        "                 opt_flow_len,\n",
        "                 chunks_per_video,\n",
        "                 batch_size,\n",
        "                 learning_rate,\n",
        "                 decay,\n",
        "                 spatial_input_name = 'spatial_input', pop_classifiers=True, filter=None, frozen_spatial=True, frozen_temporal=True, load_td_spatial_model=False, classifier_in_submodel=False, tensorboard_dir='./Models/ViewClassifier/tensorboard_logs/'):\n",
        "        self.spatial_model_name = spatial_model_name\n",
        "        self.temporal_model_name = temporal_model_name\n",
        "        self.modelname = f\"Fused_{os.path.basename(spatial_model_name)}_{os.path.basename(temporal_model_name)}\"\n",
        "        self.train_dir = train_dir\n",
        "        self.test_dir = test_dir\n",
        "        self.pop_classifiers = pop_classifiers\n",
        "        self.filter = filter\n",
        "        self.width_temporal = width_temporal\n",
        "        self.height_temporal = height_temporal\n",
        "        self.width_spatial = width_spatial\n",
        "        self.height_spatial = height_spatial\n",
        "        self.opt_flow_len = opt_flow_len\n",
        "        self.chunks_per_video = chunks_per_video\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        # if self.learning_rate == -1:\n",
        "        #     self.opt = optimizers.Adam()\n",
        "        # else:\n",
        "        self.decay = decay\n",
        "        self.opt = optimizers.Adam(learning_rate=self.learning_rate, decay=self.decay)\n",
        "\n",
        "        self.frozen_spatial = frozen_spatial\n",
        "        self.frozen_temporal = frozen_temporal\n",
        "        self.load_td_spatial_model = load_td_spatial_model\n",
        "        self.classifier_in_submodel=classifier_in_submodel\n",
        "        self.tensorboard_dir = tensorboard_dir\n",
        "        self.spatial_input_name = spatial_input_name\n",
        "        self.model_dir = os.path.dirname(os.path.dirname(tensorboard_dir))\n",
        "\n",
        "        log_dir = os.path.join(self.tensorboard_dir, self.modelname)\n",
        "        self.tbCallBack = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "        self.checkpointCallBack = ModelCheckpoint(\n",
        "            f\"{os.path.join(self.model_dir, self.modelname)}\" + \"-e{epoch:02d}-acc{val_accuracy:.3f}.hdf5\",\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "        self.generator = FusedModelGenerator(train_dir=self.train_dir,\n",
        "                                             test_dir=self.test_dir,\n",
        "                                             filter=self.filter,\n",
        "                                             num_of_snip=self.chunks_per_video,\n",
        "                                             opt_flow_len=self.opt_flow_len,\n",
        "                                             batch_size=self.batch_size,\n",
        "                                             fileext_opticalflow=\".jpg\",\n",
        "                                             fileext_spatial='.jpg',\n",
        "                                             spatial_input_name=spatial_input_name)\n",
        "\n",
        "        self.temporal_model = self.load_temporal_model()\n",
        "        self.spatial_model = self.load_spatial_model()\n",
        "        self.model = self.load_model()\n",
        "        self.train_generator = self.generator.generate_stacks('train')\n",
        "        self.test_generator = self.generator.generate_stacks('test')\n",
        "\n",
        "    def load_spatial_model(self):\n",
        "        spatial_model = load_model(self.spatial_model_name)\n",
        "        if self.classifier_in_submodel:\n",
        "            spatial_model = spatial_model.layers[0]\n",
        "        print(f\"Loaded {self.spatial_model_name} for spatial stream\")\n",
        "        if self.pop_classifiers and not self.classifier_in_submodel:\n",
        "            # print(f\"Popping classifier from spatial model\")\n",
        "            spatial_model.layers.pop()\n",
        "            # input shape (-1,-1,-1,3)\n",
        "            # output shape (-1,2048)\n",
        "            spatial_model = Model(inputs=spatial_model.layers[0].input, outputs=spatial_model.layers[-2].output)\n",
        "            spatial_model.compile(loss='categorical_crossentropy', optimizer=self.opt, metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "        if self.frozen_spatial:\n",
        "            for layer in spatial_model.layers:\n",
        "                layer.trainable = False\n",
        "        if not self.load_td_spatial_model:\n",
        "            model = Sequential(name='spatial')\n",
        "            model.add(TimeDistributed((spatial_model),\n",
        "                                      input_shape=(self.chunks_per_video,\n",
        "                                                   self.width_spatial,\n",
        "                                                   self.height_spatial,\n",
        "                                                   3),\n",
        "                                      name='spatial'))\n",
        "            model.add(GlobalAveragePooling1D())\n",
        "            #model.add(CuDNNLSTM(128, return_sequences=False))\n",
        "            #model.add(Dropout(0.4))\n",
        "            return model\n",
        "        else:\n",
        "            return spatial_model\n",
        "\n",
        "    def load_temporal_model(self):\n",
        "        temporal_model = load_model(self.temporal_model_name)\n",
        "        print(f\"Loaded {self.temporal_model_name} for temporal stream\")\n",
        "        if self.pop_classifiers:\n",
        "            # print(f\"Popping classifier from temporal model:\\n{.temporal_model.summary()}\")\n",
        "            temporal_model.layers.pop()\n",
        "            temporal_model = Model(inputs=temporal_model.layers[0].input, outputs=temporal_model.layers[-1].output)\n",
        "            temporal_model.compile(loss='categorical_crossentropy', optimizer=self.opt, metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "        if self.frozen_temporal:\n",
        "            for layer in temporal_model.layers:\n",
        "                layer.trainable = False\n",
        "        model = Sequential(name='temporal')\n",
        "\n",
        "        model.add(TimeDistributed((temporal_model),\n",
        "                                 input_shape=(self.chunks_per_video,\n",
        "                                             self.width_temporal,\n",
        "                                             self.height_temporal,\n",
        "                                            self.opt_flow_len * 2),\n",
        "                                name='temporal'))\n",
        "\n",
        "        model.add(GlobalAveragePooling1D(name=\"temporal_global_average_pooling1d\"))\n",
        "        #model.add(CuDNNLSTM(128, return_sequences=False))\n",
        "        #model.add(Dropout(0.4))\n",
        "        return model\n",
        "\n",
        "    def load_model(self):\n",
        "        if self.classifier_in_submodel:\n",
        "            # print('They try 116')\n",
        "            merge = concatenate([self.spatial_model.layers[-1].output, self.temporal_model.output])\n",
        "            outputs = Dense(self.generator.n_classes, activation='softmax')(merge)\n",
        "            model = Model([self.spatial_model.layers[0].input, self.temporal_model.input], outputs)\n",
        "\n",
        "        else:\n",
        "            # print('They try 122')\n",
        "            # print('Self.temporal_model.output = ', self.temporal_model.output)\n",
        "            merge = concatenate([self.spatial_model.output, self.temporal_model.output])\n",
        "            # print('Self generator n classes = ', self.generator.n_classes)\n",
        "            outputs = Dense(self.generator.n_classes, activation='softmax')(merge)\n",
        "            model = Model([self.spatial_model.input, self.temporal_model.input], outputs)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=self.opt, metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "        print(f\"Final model summary:\")\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "    def train(self, epochs):\n",
        "        if self.generator.test_dir:\n",
        "            self.model.fit(self.train_generator,\n",
        "                                     steps_per_epoch=self.generator.n_train // self.generator.batch_size,\n",
        "                                     # steps_per_epoch=5,\n",
        "                                     epochs=epochs,\n",
        "                                     callbacks=[self.tbCallBack, self.checkpointCallBack],\n",
        "                                     validation_data=self.test_generator,\n",
        "                                     validation_steps=self.generator.n_test // self.generator.batch_size)\n",
        "                                     # validation_steps=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "8Ppc-PIO3p8y",
        "outputId": "a4be210a-7d9f-4f0e-a3ba-cde7b056755c"
      },
      "outputs": [],
      "source": [
        "tsf = TwoStreamFused('Models/CNN_Xception-e03-acc0.926.hdf5',\n",
        "                      'Models/OF_TemporalModelInception_c-e26-acc0.65.hdf5',\n",
        "                      'Data/train',\n",
        "                      'Data/val',\n",
        "                      224, 224, 224, 224,\n",
        "                      10, #optical flow len\n",
        "                      2, #chunks per video\n",
        "                      43, #batch size\n",
        "                      2.5, #learning rate\n",
        "                      0.001 #decay\n",
        "                     )\n",
        "#default decay, bs=32, lr=1\n",
        "tsf.train(500)\n",
        "print(\"We finish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIr3nKcTLTSZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "!tar -cvf goodmodels.tar.gz Models/ViewClassifier/Fused_CNN_Xception-e03-acc0.926.hdf5_OF_TemporalModelInception_c-e26-acc0.7*\n",
        "files.download('goodmodels.tar.gz')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
